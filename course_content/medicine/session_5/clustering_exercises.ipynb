{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f569ecf",
   "metadata": {},
   "source": [
    "# Clustering Exercise  \n",
    "  \n",
    "In the `clustering.ipynb` notebook, you were given a demonstration of how dimensionality reduction and clustering can be used to do exploratory analysis of data. In this exercise, you will be carrying out this analysis yourself on a dataset that we have synthetically generated.  \n",
    "  \n",
    "You are going to be given measurements for 300 patients. There are a number of patient subtypes in the data. Your task is to identify these subtypes and clinically interpret what they may correspond to.  \n",
    "  \n",
    "You can use the skills and code from the `clustering.ipynb` notebook to help you with this exercise. If you have any questions, put your hand up and a course instructor will come over to help you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060ed4d8",
   "metadata": {},
   "source": [
    "## Method  \n",
    "  \n",
    "Follow these steps to identify the clusters \n",
    "- Use `pandas` to read in the `synthetic_clusters.csv` dataset. This has a number of observations for 300 patients. \n",
    "- Use UMAP to project this high dimensional dataset to 2 dimensions instead for visualisation. Make sure to record the `n_neighbors` and `min_dist` that you use to do this. \n",
    "- On the original data, perform K-Means or hierarchical clustering (your choice). Vary the number of clusters to identify a suitable number of clusters\n",
    "- Use the UMAP projection to visualise how these different numbers of clusters appear in the projected space. What seems to be the correct number of clusters?\n",
    "- Interpret the different clusters: for example, compare the average glucose level or BMI. What might they correspond to clinically?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa975504",
   "metadata": {},
   "source": [
    "We have got you started below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec6104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing the UMAP library to make sure we can use it\n",
    "\n",
    "src_dir = \"../../../src\"\n",
    "import sys\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "from install_if_missing import install_if_missing\n",
    "\n",
    "install_if_missing(\"umap-learn==0.5.1\", verbose=True)\n",
    "install_if_missing(\"seaborn\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6953c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing any libraries that we need to solve the problem\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "import umap.umap_ as umap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68626add",
   "metadata": {},
   "source": [
    "In order for clustering and UMAP to make sense, all of the data has to appear on the same scale. Otherwise, naturally large values (like heart rate) will skew the result more than naturally low values (like BMI). We do this using `StandardScaler` from the `sklearn` library. This performs a z-score normalisation, which normalises the values so that they have a mean of 0 and a standard deviation of 1. This keeps all of the values on the same scale, but does not change their distribution, which is important for machine learning methods to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9092a4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"dataset/synthetic_clusters.csv\")\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "df = scaler.fit_transform(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17894518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first step is to use UMAP to project the data into 2D\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
